<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python on Uncertainty...Minimized</title>
    <link>/tags/python/</link>
    <description>Recent content in Python on Uncertainty...Minimized</description>
    <generator>Hugo -- gohugo.io</generator>
    <managingEditor>mj514316@domain.com (Michael C Johnson)</managingEditor>
    <webMaster>mj514316@domain.com (Michael C Johnson)</webMaster>
    <lastBuildDate>Wed, 19 Jun 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/python/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Graph Visualization of The Mueller Report With SpaCy and PyVis</title>
      <link>/post/graph-visualization-of-the-mueller-report-with-spacy-and-pyvis/</link>
      <pubDate>Wed, 19 Jun 2019 00:00:00 +0000</pubDate>
      <author>mj514316@domain.com (Michael C Johnson)</author>
      <guid>/post/graph-visualization-of-the-mueller-report-with-spacy-and-pyvis/</guid>
      <description>One of the most interesting talks I heard at Strata in San Francisco this year was “Towards deep and representation learning for talent search at LinkedIn”. In the talk, Gungor explained how he took advantage of LinkedIn’s economic graph to build a hyper-personalized search engine. Ever since then I’ve had graphs firmly planted in my mind.
Not these graphs:
Graph
More like these:
Network
Specifically, I’ve been trying to understand how graph network techniques can be applied in various domains, including natural language processing.</description>
    </item>
    
    <item>
      <title>Monte Carlo Simulation For Childrens Stories</title>
      <link>/post/statistically-verifying-claims-made-in-childrens-stories/</link>
      <pubDate>Fri, 25 Jan 2019 00:00:00 +0000</pubDate>
      <author>mj514316@domain.com (Michael C Johnson)</author>
      <guid>/post/statistically-verifying-claims-made-in-childrens-stories/</guid>
      <description>Bedtime has historically been a battle for our family. Kids have this impressive ability to fall asleep when you want them awake and vigorously stay awake when you want them to sleep. To combat the insanity, we read a few books every night before bed. There is a great series of books for young children called &amp;ldquo;The Magic Tree House&amp;rdquo;. The series follows two children (Jack and Annie) who transport to other times and places for some mystery or adventure.</description>
    </item>
    
    <item>
      <title>Deep Autoencoder Neural Networks for Maximal Christmas Decoration Enjoyment</title>
      <link>/post/deep-autoencoder-neural-networks-for-maximal-christmas-decoration-enjoyment/</link>
      <pubDate>Wed, 21 Nov 2018 00:00:00 +0000</pubDate>
      <author>mj514316@domain.com (Michael C Johnson)</author>
      <guid>/post/deep-autoencoder-neural-networks-for-maximal-christmas-decoration-enjoyment/</guid>
      <description>My wife loves decorations. From Valentines Day to Easter to Thanksgiving, our house is adorned with interesting festive items. Her favorite season by far is Christmas. Every December we drive around trying to find the best Christmas lights. Inevitably, there are a few houses with lights that blink with the music, something I&amp;rsquo;ve always been fascinated with.
Two years ago I embarked on a mission to build my own Christmas Light Show, specifically this is what I had in mind:</description>
    </item>
    
  </channel>
</rss>