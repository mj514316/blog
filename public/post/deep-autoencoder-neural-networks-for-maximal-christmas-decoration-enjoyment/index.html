<!DOCTYPE html>
<html lang="en" itemscope itemtype="http://schema.org/WebPage">
  <head>
    

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">

  <title>Deep Autoencoder Neural Networks for Maximal Christmas Decoration Enjoyment - Uncertainty...Minimized</title>
  <meta property="og:title" content="Deep Autoencoder Neural Networks for Maximal Christmas Decoration Enjoyment" />
  <meta name="twitter:title" content="Deep Autoencoder Neural Networks for Maximal Christmas Decoration …" />
  <meta name="description" content="My wife loves decorations. From Valentines Day to Easter to Thanksgiving, our house is adorned with interesting festive items. Her favorite season by far is Christmas. Every December we drive around trying to find the best Christmas lights. Inevitably, there are a few houses with lights that blink with the music, something I&rsquo;ve always been fascinated with.
Two years ago I embarked on a mission to build my own Christmas Light Show, specifically this is what I had in mind:">
  <meta property="og:description" content="My wife loves decorations. From Valentines Day to Easter to Thanksgiving, our house is adorned with interesting festive items. Her favorite season by far is Christmas. Every December we drive around trying to find the best Christmas lights. Inevitably, there are a few houses with lights that blink with the music, something I&rsquo;ve always been fascinated with.
Two years ago I embarked on a mission to build my own Christmas Light Show, specifically this is what I had in mind:">
  <meta name="twitter:description" content="My wife loves decorations. From Valentines Day to Easter to Thanksgiving, our house is adorned with interesting festive items. Her favorite season by far is Christmas. Every December we drive around …">
  <meta name="author" content="Michael C Johnson"/><script type="application/ld+json">
{
    "@context": "http://schema.org",
    "@type": "WebSite",
    "name": "Uncertainty...Minimized",
    
    "url": "/"
}
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Organization",
  "name": "",
  "url": "/"
  
  
  
  
}
</script>
<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [{
        "@type": "ListItem",
        "position": 1,
        "item": {
          "@id": "/",
          "name": "home"
        }
    },{
        "@type": "ListItem",
        "position": 3,
        "item": {
          "@id": "/post/deep-autoencoder-neural-networks-for-maximal-christmas-decoration-enjoyment/",
          "name": "Deep autoencoder neural networks for maximal christmas decoration enjoyment"
        }
    }]
}
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Article",
  "author": {
    "name" : "Michael C Johnson"
  },
  "headline": "Deep Autoencoder Neural Networks for Maximal Christmas Decoration Enjoyment",
  "description" : "My wife loves decorations. From Valentines Day to Easter to Thanksgiving, our house is adorned with interesting festive items. Her favorite season by far is Christmas. Every December we drive around trying to find the best Christmas lights. Inevitably, there are a few houses with lights that blink with the music, something I&amp;rsquo;ve always been fascinated with.
Two years ago I embarked on a mission to build my own Christmas Light Show, specifically this is what I had in mind:",
  "inLanguage" : "en",
  "wordCount": 1528,
  "datePublished" : "2018-11-21T00:00:00",
  "dateModified" : "2018-11-21T00:00:00",
  "image" : "/img/LightShowPipeline.jpg",
  "keywords" : [ "Deep Learning, Raspberry Pi, python, Keras, tensorflow, Christmas, FFT, Autoencoder" ],
  "mainEntityOfPage" : "/post/deep-autoencoder-neural-networks-for-maximal-christmas-decoration-enjoyment/",
  "publisher" : {
    "@type": "Organization",
    "name" : "/",
    "logo" : {
        "@type" : "ImageObject",
        "url" : "/img/LightShowPipeline.jpg",
        "height" :  60 ,
        "width" :  60
    }
  }
}
</script>

<meta property="og:title" content="Deep Autoencoder Neural Networks for Maximal Christmas Decoration Enjoyment" />
<meta property="og:description" content="My wife loves decorations. From Valentines Day to Easter to Thanksgiving, our house is adorned with interesting festive items. Her favorite season by far is Christmas. Every December we drive around trying to find the best Christmas lights. Inevitably, there are a few houses with lights that blink with the music, something I&rsquo;ve always been fascinated with.
Two years ago I embarked on a mission to build my own Christmas Light Show, specifically this is what I had in mind:">
<meta property="og:image" content="/img/LightShowPipeline.jpg" />
<meta property="og:url" content="/post/deep-autoencoder-neural-networks-for-maximal-christmas-decoration-enjoyment/" />
<meta property="og:type" content="website" />
<meta property="og:site_name" content="Uncertainty...Minimized" />
  <meta name="twitter:title" content="Deep Autoencoder Neural Networks for Maximal Christmas Decoration …" />
  <meta name="twitter:description" content="My wife loves decorations. From Valentines Day to Easter to Thanksgiving, our house is adorned with interesting festive items. Her favorite season by far is Christmas. Every December we drive around …">
  <meta name="twitter:image" content="/img/LightShowPipeline.jpg" />
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:site" content="@Michael24909206" />
  <meta name="twitter:creator" content="@Michael24909206" />
  <link href='/img/favicon.ico' rel='icon' type='image/x-icon'/>
  <meta property="og:image" content="/img/LightShowPipeline.jpg" />
  <meta name="twitter:image" content="/img/LightShowPipeline.jpg" />
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:site" content="@Michael24909206" />
  <meta name="twitter:creator" content="@Michael24909206" />
  <meta property="og:url" content="/post/deep-autoencoder-neural-networks-for-maximal-christmas-decoration-enjoyment/" />
  <meta property="og:type" content="website" />
  <meta property="og:site_name" content="Uncertainty...Minimized" />

  <meta name="generator" content="Hugo 0.51" />
  <link rel="alternate" href="/index.xml" type="application/rss+xml" title="Uncertainty...Minimized">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css" integrity="sha384-9eLZqc9ds8eNjO3TmqPeYcDj8n+Qfa4nuSiGYa6DjLNcv9BtN69ZIulL9+8CqC9Y" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.5.0/css/all.css" integrity="sha384-B4dIYHKNBt8Bc12p+WXckhzcICo0wtJAoU8YZTY5qE0Id1GSseTk6S+L3BlXeVIU" crossorigin="anonymous">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
  <link rel="stylesheet" href="/css/main.css" /><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" />
  <link rel="stylesheet" href="/css/highlight.min.css" /><link rel="stylesheet" href="/css/codeblock.css" /><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.css" integrity="sha384-h/L2W9KefUClHWaty3SLE5F/qvc4djlyR4qY3NUV5HGQBBW7stbcfff1+I/vmsHh" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/default-skin/default-skin.min.css" integrity="sha384-iD0dNku6PYSIQLyfTOpB06F2KCZJAKLOThS5HRe8b3ibhdEQ6eKsFf/EeFxdOt5R" crossorigin="anonymous">



<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-129788260-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


  </head>
  <body>
    <nav class="navbar navbar-default navbar-fixed-top navbar-custom">
  <div class="container-fluid">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#main-navbar">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="/">Uncertainty...Minimized</a>
    </div>

    <div class="collapse navbar-collapse" id="main-navbar">
      <ul class="nav navbar-nav navbar-right">
        
          
            <li>
              <a title="Blog" href="/">Blog</a>
            </li>
          
        
          
            <li>
              <a title="About" href="/page/about/">About</a>
            </li>
          
        
          
            <li>
              <a title="Tags" href="/tags">Tags</a>
            </li>
          
        

        

        
      </ul>
    </div>

    
      <div class="avatar-container">
        <div class="avatar-img-border">
          <a title="Uncertainty...Minimized" href="/">
            <img class="avatar-img" src="/img/LightShowPipeline.jpg" alt="Uncertainty...Minimized" />
          </a>
        </div>
      </div>
    

  </div>
</nav>




    


<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

<div class="pswp__bg"></div>

<div class="pswp__scroll-wrap">
    
    <div class="pswp__container">
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
    </div>
    
    <div class="pswp__ui pswp__ui--hidden">
    <div class="pswp__top-bar">
      
      <div class="pswp__counter"></div>
      <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
      <button class="pswp__button pswp__button--share" title="Share"></button>
      <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
      <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
      
      
      <div class="pswp__preloader">
        <div class="pswp__preloader__icn">
          <div class="pswp__preloader__cut">
            <div class="pswp__preloader__donut"></div>
          </div>
        </div>
      </div>
    </div>
    <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
      <div class="pswp__share-tooltip"></div>
    </div>
    <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
    </button>
    <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
    </button>
    <div class="pswp__caption">
      <div class="pswp__caption__center"></div>
    </div>
    </div>
    </div>
</div>


  
  
  






  

  <header class="header-section ">
    
    <div class="intro-header no-img">
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
            <div class="post-heading">
              
                <h1>Deep Autoencoder Neural Networks for Maximal Christmas Decoration Enjoyment</h1>
              
              
              
              
                <span class="post-meta">
  
  
  <i class="fas fa-calendar"></i>&nbsp;Posted on November 21, 2018
  
  
    &nbsp;|&nbsp;<i class="fas fa-clock"></i>&nbsp;8&nbsp;minutes
  
  
    &nbsp;|&nbsp;<i class="fas fa-book"></i>&nbsp;1528&nbsp;words
  
  
    &nbsp;|&nbsp;<i class="fas fa-user"></i>&nbsp;Michael C Johnson
  
  
</span>


              
            </div>
          </div>
        </div>
      </div>
    </div>
  </header>


    
<div class="container" role="main">
  <div class="row">
    <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
      <article role="main" class="blog-post">
        

<p>My wife loves decorations. From Valentines Day to Easter to Thanksgiving, our house is adorned with interesting festive items. Her favorite season by far is Christmas. Every December we drive around trying to find the best Christmas lights. Inevitably, there are a few houses with lights that blink with the music, something I&rsquo;ve always been fascinated with.<br />
Two years ago I embarked on a mission to build my own Christmas Light Show, specifically this is what I had in mind:</p>

<ol>
<li>Break music up into even sized chunks<br /></li>
<li>Convert each chunk into frequency components using <a href="https://en.wikipedia.org/wiki/Discrete_Fourier_transform">FFT</a><br /></li>
<li>Bucketize frequencies into the number of light channels<br /></li>
<li>Activate a light channel when the decibels reached a certain threshold:<br /></li>
</ol>

<p><img src="/img/LightShowPipeline.jpg" alt="Light Show Pipeline" /></p>

<p>A brief Google investigation revealed I had been (thankfully) beaten to the chase. The open source <a href="http://lightshowpi.org/">lightshowpi</a> project already had a full pipeline, took like 10 minutes to set up, and already had the FFT parallelized on the Raspberry Pi GPU (so you can apply it to streaming music!). Here is a video of our light show the first year (Christmas tree only):</p>

<p><!--html_preserve-->
<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="//www.youtube.com/embed/aAiQ7VSyrno" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>
<!--/html_preserve--></p>

<p>What I&rsquo;ve found over the past few years is that while the light show is certainly entertaining (After every song, every year, my kids have a deep expression of joy and clap and congratulate me on my show), I&rsquo;ve been interested in ways to capture more of the structure of the sound in the blinking lights. The light blinking can be sporadic (especially during very fast parts of the song), and vocals are not always captured very well across vocal range.</p>

<h2 id="enter-deep-autoencoder-neural-networks">Enter: Deep Autoencoder Neural Networks</h2>

<p>Autoencoders are intuitive networks that have a simple premise: reconstruct an input from an output while learning a compressed representation of the data. This is accomplished by squeezing the network in the middle, forcing the network to compress x inputs into y intermediate outputs, where x&gt;&gt;y. <a href="https://blog.keras.io/building-autoencoders-in-keras.html">Here</a> is a nice blog post from the Keras blog that goes into some detail on autoencoders for the mnist dataset.</p>

<p><img src="/img/Autoencoder.jpg" alt="Generic AutoEncoder" /></p>

<p>So what exactly are we going to squeeze? Once you&rsquo;ve processed the signal through the FFT, you can make a spectrogram (check out <a href="https://www.youtube.com/watch?v=_FatxGN3vAM">this</a> super psyched YouTube video)&hellip; Time is on the x-axis, frequency is on the y, and the color represents the amplitude for that time/frequency. If you had a tuning fork tuned for a pure <a href="http://pages.mtu.edu/~suits/notefreqs.html">A4 note</a> you&rsquo;d have a solid (in this case red) line at 440Hz. The song we&rsquo;ll study for the rest of the post is &ldquo;<a href="https://www.youtube.com/watch?v=6P9xxJ4V7no">A Mad Russian&rsquo;s Christmas</a>&rdquo; by The Trans Siberian Orchestra, check out the spectrogram:<br />
<img src="/img/madRussianOrig.jpg" alt="A Mad Russian's Christmas" /></p>

<p>I encourage you to look at the spectrogram while you listen to the song, see if you can pick out the different sections. You&rsquo;ll also notice why our simple heuristic method (frequency buckets + thresholding) doesn&rsquo;t do a great job capturing the structure of the song. If you look closely at the spectrogram you notice characteristic bands representing the complex sounds span many frequencies.</p>

<p>Since the ultimate goal is to light up different Christmas lights at different rhythms in the song, what we need to do is to learn a compressed representation of the audio input <em>at each time step</em>. The spectrogram works perfectly for this. There are 513 frequency &lsquo;features&rsquo; at each time step, so the goal of our autoencoder will be to build an 8-channel representation of each time step (To match the number of light channels). Note that this is essentially a dimensionality reduction technique, and the standard set of algorithms could be applied here (PCA and tSNE are my favorite, perhaps we&rsquo;ll do another post on those<sup class="footnote-ref" id="fnref:1"><a href="#fn:1">1</a></sup>). Something like this:</p>

<p><img src="/img/AutoencoderSpectrogram.jpg" alt="Autoencoder For Spectrogram" /></p>

<p>We&rsquo;ll train &ldquo;A Mad Russian&rsquo;s Christmas&rdquo; and test on &ldquo;Christmas Sarajevo&rdquo;. First, lets get some setup out of the way:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">spectrogramUtils</span> <span class="kn">import</span> <span class="o">*</span> <span class="c1">#(Check Bitbucket link for this file. Or use pyplot.specgram....)</span>

<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Dropout</span></code></pre></div><div class="highlight"><pre class="chroma">## C:\Users\mj514\ANACON~1\lib\site-packages\h5py\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
##   from ._conv import register_converters as _register_converters
## Using TensorFlow backend.</pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Model</span></code></pre></div>
<p>Now, create extract the spectrograms out of the the data. Here is a code snippet that will convert your <strong>entire</strong> music library into .wav (make sure you have ffmpeg installed first) :</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">os</span><span class="o">,</span> <span class="nn">re</span><span class="o">,</span> <span class="nn">subprocess</span>
<span class="n">paths</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">r</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">walk</span><span class="p">(</span><span class="s1">&#39;C:/Users/mj514/Music/&#39;</span><span class="p">):</span>
    <span class="k">for</span> <span class="nb">file</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">if</span> <span class="s2">&#34;.mp3&#34;</span> <span class="ow">in</span> <span class="nb">file</span><span class="p">:</span>
            <span class="n">strippedFileName</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;[^A-Za-z0-9-mp3]+&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="nb">file</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="p">)</span><span class="c1">#remove special characters and file ending</span>
            <span class="n">strippedFileName</span> <span class="o">=</span> <span class="n">strippedFileName</span>
            <span class="n">paths</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">r</span> <span class="o">+</span> <span class="s1">&#39;/&#39;</span> <span class="o">+</span> <span class="nb">file</span><span class="p">,</span><span class="n">strippedFileName</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">aTuple</span> <span class="ow">in</span> <span class="n">paths</span><span class="p">:</span>
      <span class="n">subprocess</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;ffmpeg -i &#34;{aTuple[0]}&#34; wavs\{aTuple[1]}.wav&#39;</span><span class="p">,</span> <span class="n">shell</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span></code></pre></div>
<p>The plotstft function (from spectrogramUtils, adapted from <a href="http://www.frank-zalkow.de/en/code-snippets/create-audio-spectrograms-with-python.html">here</a>) breaks our song up into frequency components, and returns a .npy array with 513 features and some number of time step features.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">madIms</span> <span class="o">=</span> <span class="n">plotstft</span><span class="p">(</span><span class="s1">&#39;C:/Users/mj514/Documents/dataSci/christmasAutoencoder/maddrussian.wav&#39;</span><span class="p">)</span></code></pre></div>
<p><img src="2018-11-21-deep-autoencoder-neural-networks-for-maximal-christmas-decoration-enjoyment_files/figure-html/unnamed-chunk-5-1.png" alt="" /><!-- --></p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">christmasSarajevoIms</span> <span class="o">=</span> <span class="n">plotstft</span><span class="p">(</span><span class="s1">&#39;C:/Users/mj514/Documents/dataSci/christmasAutoencoder/christmasSerajevo.wav&#39;</span><span class="p">)</span></code></pre></div>
<p><img src="2018-11-21-deep-autoencoder-neural-networks-for-maximal-christmas-decoration-enjoyment_files/figure-html/unnamed-chunk-5-2.png" alt="" /><!-- --></p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&#34;Class: {madIms.__class__}, shape: {madIms.shape}&#34;</span><span class="p">)</span> <span class="c1"># I recently fell in love with fstrings!!!</span></code></pre></div><div class="highlight"><pre class="chroma">## Class: &lt;class &#39;numpy.ndarray&#39;&gt;, shape: (24330, 513)</pre></div>
<p>Here I chose to do min-max scaling, as my input has a predictable amplitude. I build the transformation on the train song (madIms) and apply it to the test song(christmasSarajevoIms)</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">madIms</span><span class="p">)</span> 
<span class="n">x_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">christmasSarajevoIms</span><span class="p">)</span></code></pre></div>
<p>Next, let&rsquo;s set up our autoencoder. As you can see the encoder steps progressively down until we get to the desired number of channels, and the decoder steps the input back up to the full 513 output. While the measured loss doesn&rsquo;t improve significantly with added layers ( you can get the same network performance with only 1 hidden layer) I found that the intermediate features are mutch richer with a full encode-decode stack.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">denseAutoencoder</span><span class="p">(</span><span class="n">internalActivation</span> <span class="o">=</span> <span class="s1">&#39;tanh&#39;</span><span class="p">):</span>
    <span class="n">input_img</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">513</span><span class="p">,))</span>
    <span class="n">input_dropped</span> <span class="o">=</span> <span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">)(</span><span class="n">input_img</span><span class="p">)</span>
    <span class="n">encoded</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">internalActivation</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;encode_128&#39;</span><span class="p">)(</span><span class="n">input_dropped</span><span class="p">)</span>
    <span class="n">encoded</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">internalActivation</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;encode_64&#39;</span><span class="p">)(</span><span class="n">encoded</span><span class="p">)</span>
    <span class="n">encoded</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">internalActivation</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;encode_32&#39;</span><span class="p">)(</span><span class="n">encoded</span><span class="p">)</span>
    <span class="n">encoded</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">internalActivation</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;encode_16&#39;</span><span class="p">)(</span><span class="n">encoded</span><span class="p">)</span>
    <span class="n">encoded</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">internalActivation</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;encode_8&#39;</span><span class="p">)(</span><span class="n">encoded</span><span class="p">)</span>

    <span class="n">decoded</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">internalActivation</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;decode_16&#39;</span><span class="p">)(</span><span class="n">encoded</span><span class="p">)</span>
    <span class="n">decoded</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">internalActivation</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;decode_32&#39;</span><span class="p">)(</span><span class="n">decoded</span><span class="p">)</span>
    <span class="n">decoded</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">internalActivation</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;decode_64&#39;</span><span class="p">)(</span><span class="n">decoded</span><span class="p">)</span>
    <span class="n">decoded</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">internalActivation</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;decode_128&#39;</span><span class="p">)(</span><span class="n">decoded</span><span class="p">)</span>
    <span class="n">decoded</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">513</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;output&#39;</span><span class="p">)(</span><span class="n">decoded</span><span class="p">)</span>

    <span class="n">autoencoderDense</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">input_img</span><span class="p">,</span> <span class="n">decoded</span><span class="p">)</span>
    <span class="n">autoencoderDense</span><span class="o">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mean_squared_error&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">autoencoderDense</span>
    
<span class="n">autoencoderDense</span> <span class="o">=</span> <span class="n">denseAutoencoder</span><span class="p">()</span>
<span class="n">autoencoderDense</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span>
                <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
                <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="c1">#important</span>
                <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">x_test</span><span class="p">))</span></code></pre></div>
<p>It turns out that for this network, tanh activation was better than relu and sigmoid. I suspect tanh was better than relu in this case because of the inherent non linear nature of sound. Looking at the distribution of magnitudes, there isn&rsquo;t much of a skew, so maybe I&rsquo;m wrong:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">madIms</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span><span class="n">bins</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span></code></pre></div>
<p><img src="/img/magnitudeHistogram.jpg" alt="Distribution of magnitudes" />
While it can be tempting to assume the default (in this case relu) is the best activation, it&rsquo;s always best to explore.</p>

<h2 id="analyze-output">Analyze Output</h2>

<p>So how well did we do? Lets look at the reconstructed (top) and the original (bottom):
<img src="/img/reconstructed.png" alt="Reconstructed" />
<img src="/img/orig.png" alt="orig" /></p>

<p>The reconstructed is significantly less noisy (one of the applications for autoencoders), but seems to do a good job capturing the basic structure.</p>

<p>The final step is to clip off the decode layers and get the activations for the intermediate layers:
<img src="/img/AutoencoderWithLights.jpg" alt="Christmas Autoencoder" /></p>

<p>To do this, we can use the keract package</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">keract</span> <span class="kn">import</span> <span class="n">get_activations</span>
<span class="n">active</span> <span class="o">=</span> <span class="n">get_activations</span><span class="p">(</span><span class="n">autoencoderDense</span><span class="p">,</span> <span class="n">x_test</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="p">{</span><span class="k">print</span><span class="p">(</span><span class="n">k</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">v</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">active</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>

<span class="c1">## dropout_1/cond/Merge:0(17686, 513)</span>
<span class="c1">## encode_128/Tanh:0(17686, 128)</span>
<span class="c1">## encode_64/Tanh:0(17686, 64)</span>
<span class="c1">## encode_32/Tanh:0(17686, 32)</span>
<span class="c1">## encode_16/Tanh:0(17686, 16)</span>
<span class="c1">## encode_8/Tanh:0(17686, 8) # this is the one we want</span>
<span class="c1">## decode_16/Tanh:0(17686, 16)</span>
<span class="c1">## decode_32/Tanh:0(17686, 32)</span>
<span class="c1">## decode_64/Tanh:0(17686, 64)</span>
<span class="c1">## decode_128/Tanh:0(17686, 128)</span>
<span class="c1">## output/Sigmoid:0(17686, 513)</span>

<span class="n">intermediateLayerName</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">active</span><span class="o">.</span><span class="n">keys</span><span class="p">())[</span><span class="mi">5</span><span class="p">]</span></code></pre></div>
<p>Plotting the activations of the encode_8 layer over time gives:</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mf">6.5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">active</span><span class="p">[</span><span class="n">intermediateLayerName</span><span class="p">],</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span></code></pre></div>
<p><img src="/img/smallAutoEncoded.jpg" alt="Small Autoencoded" />
Here is a super zoomed version (you have to click the graph, I promise it&rsquo;s worth it.)



<div class="gallery caption-position-bottom caption-effect-slide hover-effect-zoom hover-transition" itemscope itemtype="http://schema.org/ImageGallery">
	  

<link rel="stylesheet" href="/css/hugo-easy-gallery.css" />
<div class="box" >
  <figure  itemprop="associatedMedia" itemscope itemtype="http://schema.org/ImageObject">
    <div class="img" style="background-image: url('//img/bigAutoEncoded.jpg');">
      <img itemprop="thumbnail" src="/img/bigAutoEncoded.jpg" alt="Large Autoencoded"/>
    </div>
    <a href="/img/bigAutoEncoded.jpg" itemprop="contentUrl"></a>
      <figcaption>
          <p>Large Autoencoded</p>
      </figcaption>
  </figure>
</div>


</div>

Each of the 8 channels seem to be most active at individual portions of the song. It&rsquo;s also clear from this analysis that individual sections of the song are well diferentiated by the outputs.</p>

<h2 id="conclusion">Conclusion</h2>

<p>It turns out, not even Christmas Lights are safe from the oncoming <a href="https://www.youtube.com/watch?v=21EiKfQYZXc">AI revolution</a>! This analysis leaves room for quite a bit of additional exploration:</p>

<ul>
<li>Does the reconstruction work well on songs from other artists/in other genres?</li>
<li>Is there a way to use stereo sound (only used one side of the input here) to improve the reconstruction and thus the quality of the compressed signal?</li>
<li>What other architectures could be used? (CNN,RNN)</li>
<li>Can we classify the songs based on artist or genre?</li>
<li>Can we get it working on the Raspberry Pi?<br /></li>
</ul>

<p>For the next post, we&rsquo;ll be exploring how to improve the encoding by removing the end bits from the song, allowing the intermediate features to capture a richer representation of the important parts of the song. I&rsquo;ll also show how we can use a 1D Convolutional Network to build a more accurate reconstruction. Do you have other ideas? <strong>Comment below to let me know!</strong></p>
<div class="footnotes">

<hr />

<ol>
<li id="fn:1">There is a problem with tSNE for this application. Because tSNE is non parametric, you cannot translate &lsquo;new&rsquo; inputs into the tSNE space. Effectively you would need to rebuild tSNE for every song. This could presumably be done offline if you have fixed songs, but won&rsquo;t work for the streaming case and is computationally expensive for a Raspberry Pi application.
 <a class="footnote-return" href="#fnref:1"><sup>[return]</sup></a></li>
</ol>
</div>


        
          <div class="blog-tags">
            
              <a href="//tags/deep-learning/">Deep Learning</a>&nbsp;
            
              <a href="//tags/raspberry-pi/">Raspberry Pi</a>&nbsp;
            
              <a href="//tags/python/">python</a>&nbsp;
            
              <a href="//tags/keras/">Keras</a>&nbsp;
            
              <a href="//tags/tensorflow/">tensorflow</a>&nbsp;
            
              <a href="//tags/christmas/">Christmas</a>&nbsp;
            
              <a href="//tags/fft/">FFT</a>&nbsp;
            
              <a href="//tags/autoencoder/">Autoencoder</a>&nbsp;
            
          </div>
        

        
            <hr/>
            <section id="social-share">
              <div class="list-inline footer-links">
                

<div class="share-box" aria-hidden="true">
    <ul class="share">
      
      <li>
        <a href="//twitter.com/share?url=%2fpost%2fdeep-autoencoder-neural-networks-for-maximal-christmas-decoration-enjoyment%2f&amp;text=Deep%20Autoencoder%20Neural%20Networks%20for%20Maximal%20Christmas%20Decoration%20Enjoyment&amp;via=Michael24909206" target="_blank" title="Share on Twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//plus.google.com/share?url=%2fpost%2fdeep-autoencoder-neural-networks-for-maximal-christmas-decoration-enjoyment%2f" target="_blank" title="Share on Google Plus">
          <i class="fab fa-google-plus"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.facebook.com/sharer/sharer.php?u=%2fpost%2fdeep-autoencoder-neural-networks-for-maximal-christmas-decoration-enjoyment%2f" target="_blank" title="Share on Facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//reddit.com/submit?url=%2fpost%2fdeep-autoencoder-neural-networks-for-maximal-christmas-decoration-enjoyment%2f&amp;title=Deep%20Autoencoder%20Neural%20Networks%20for%20Maximal%20Christmas%20Decoration%20Enjoyment" target="_blank" title="Share on Reddit">
          <i class="fab fa-reddit"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.linkedin.com/shareArticle?url=%2fpost%2fdeep-autoencoder-neural-networks-for-maximal-christmas-decoration-enjoyment%2f&amp;title=Deep%20Autoencoder%20Neural%20Networks%20for%20Maximal%20Christmas%20Decoration%20Enjoyment" target="_blank" title="Share on LinkedIn">
          <i class="fab fa-linkedin"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.stumbleupon.com/submit?url=%2fpost%2fdeep-autoencoder-neural-networks-for-maximal-christmas-decoration-enjoyment%2f&amp;title=Deep%20Autoencoder%20Neural%20Networks%20for%20Maximal%20Christmas%20Decoration%20Enjoyment" target="_blank" title="Share on StumbleUpon">
          <i class="fab fa-stumbleupon"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.pinterest.com/pin/create/button/?url=%2fpost%2fdeep-autoencoder-neural-networks-for-maximal-christmas-decoration-enjoyment%2f&amp;description=Deep%20Autoencoder%20Neural%20Networks%20for%20Maximal%20Christmas%20Decoration%20Enjoyment" target="_blank" title="Share on Pinterest">
          <i class="fab fa-pinterest"></i>
        </a>
      </li>
    </ul>
  </div>
  
              </div>
            </section>
        

        
          
          
        
      </article>

      
        <ul class="pager blog-pager">
          
          
        </ul>
      


      
        
          
          <div class="disqus-comments">                  
            <button id="show-comments" class="btn btn-default" type="button">Show <span class="disqus-comment-count" data-disqus-url="post/deep-autoencoder-neural-networks-for-maximal-christmas-decoration-enjoyment">comments</span></button>
            <div id="disqus_thread"></div>

            <script type="text/javascript">
              var disqus_config = function () {
              this.page.url = 'post\/deep-autoencoder-neural-networks-for-maximal-christmas-decoration-enjoyment';
            };

          </script>
          </div>
          
        
        
      

    </div>
  </div>
</div>

    <footer>
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <ul class="list-inline text-center footer-links">
          
              <li>
                <a href="mailto:mj514316@domain.com" title="Email me">
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fas fa-envelope fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
                <a href="https://github.com/mj514316" title="GitHub">
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
                <a href="https://bitbucket.org/mj514316" title="Bitbucket">
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fab fa-bitbucket fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
                <a href="https://twitter.com/Michael24909206" title="Twitter">
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fab fa-twitter fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
                <a href="https://linkedin.com/in/michael-johnson-5105a053" title="LinkedIn">
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fab fa-linkedin fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
          
          <li>
            
            <a href="/index.xml" title="RSS">
            
              <span class="fa-stack fa-lg">
                <i class="fas fa-circle fa-stack-2x"></i>
                <i class="fas fa-rss fa-stack-1x fa-inverse"></i>
              </span>
            </a>
          </li>
          
        </ul>
        <p class="credits copyright text-muted">
          
            
              Michael C Johnson
            
          

          &nbsp;&bull;&nbsp;&copy;
          
            2018
          

          
            &nbsp;&bull;&nbsp;
            <a href="/">Uncertainty...Minimized</a>
          
        </p>
        
        <p class="credits theme-by text-muted">
          <a href="http://gohugo.io">Hugo v0.51</a> powered &nbsp;&bull;&nbsp; Theme by <a href="http://deanattali.com/beautiful-jekyll/">Beautiful Jekyll</a> adapted to <a href="https://github.com/halogenica/beautifulhugo">Beautiful Hugo</a>
          
        </p>
      </div>
    </div>
  </div>
</footer>

<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.js" integrity="sha384-K3vbOmF2BtaVai+Qk37uypf7VrgBubhQreNQe9aGsz9lB63dIFiQVlJbr92dw2Lx" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/contrib/auto-render.min.js" integrity="sha384-kmZOZB5ObwgQnS/DuDg6TScgOiWWBiVt0plIRkZCmE6rDZGrEOQeHM5PcHi+nyqe" crossorigin="anonymous"></script>
<script src="https://code.jquery.com/jquery-1.12.4.min.js" integrity="sha256-ZosEbRLbNQzLpnKIkEdrPv7lOy9C27hHQ+Xp8a4MxAQ=" crossorigin="anonymous"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<script src="/js/main.js"></script>
<script src="/js/highlight.min.js"></script>
<script> hljs.initHighlightingOnLoad(); </script>
<script> $(document).ready(function() {$("pre.chroma").css("padding","0");}); </script><script> renderMathInElement(document.body); </script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.js" integrity="sha384-QELNnmcmU8IR9ZAykt67vGr9/rZJdHbiWi64V88fCPaOohUlHCqUD/unNN0BXSqy" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe-ui-default.min.js" integrity="sha384-m67o7SkQ1ALzKZIFh4CiTA8tmadaujiTa9Vu+nqPSwDOqHrDmxLezTdFln8077+q" crossorigin="anonymous"></script>
<script src="/js/load-photoswipe.js"></script>







<script type="text/javascript">
$(function(){
  $('#show-comments').on('click', function(){
    var disqus_shortname = 'minimizeuncertainty';
      
    (function() {
      var disqus = document.createElement('script'); 
      disqus.type = 'text/javascript'; 
      disqus.async = true;
      disqus.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(disqus);
    })();
      
    $(this).hide(); 
    });
  });
      
</script>
<script id="dsq-count-scr" src="//minimizeuncertainty.disqus.com/count.js" async></script>




  </body>
</html>

